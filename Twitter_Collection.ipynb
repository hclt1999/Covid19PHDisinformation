{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Twitter_Collection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOFq2vo0zuvvPPuDWzR8pBS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"DT51MCi5TeJu"},"source":["# For sending GET requests from the API\n","import requests\n","# For saving access tokens and for file management when creating and adding to the dataset\n","import os\n","# For dealing with json responses we receive from the API\n","import json\n","# For displaying the data after\n","import pandas as pd\n","# For saving the response data in CSV format\n","import csv\n","# For parsing the dates received from twitter in readable formats\n","import datetime\n","import dateutil.parser\n","import unicodedata\n","#To add wait time between requests\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cpdAu9gAThMc"},"source":["os.environ['TOKEN'] = ''\n","\n","def auth():\n","    return os.getenv('TOKEN')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TJN2LM7EToZb"},"source":["def create_headers(bearer_token):\n","    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n","    return headers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3qxMbf8TrU0"},"source":["def create_url(keyword, start_date, end_date, max_results = 100):\n","    \n","    search_url = \"https://api.twitter.com/2/tweets/search/recent\" #Change to the endpoint you want to collect data from\n","\n","    #change params based on the endpoint you are using\n","    query_params = {'query': keyword,\n","                    'start_time': start_date,\n","                    'end_time': end_date,\n","                    'max_results': max_results,\n","                    'expansions': 'author_id,in_reply_to_user_id,geo.place_id',\n","                    'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n","                    'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n","                    'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n","                    'next_token': {}}\n","    return (search_url, query_params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dbXSDiC0T2NB"},"source":["def connect_to_endpoint(url, headers, params, next_token = None):\n","    params['next_token'] = next_token   #params object received from create_url function\n","    response = requests.request(\"GET\", url, headers = headers, params = params)\n","    print(\"Endpoint Response Code: \" + str(response.status_code))\n","    if response.status_code != 200:\n","        raise Exception(response.status_code, response.text)\n","    return response.json()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MYZhjcLf31mE"},"source":["#Inputs for the request\n","bearer_token = auth()\n","headers = create_headers(bearer_token)\n","keyword = \"#covid19ph lang:tl\"\n","start_time = \"2021-09-09T00:00:00.000Z\"\n","end_time = \"2021-09-10T00:00:00.000Z\"\n","max_results = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"odX8nHbMT9Et"},"source":["#url = create_url(keyword, start_time,end_time, max_results)\n","#json_response = connect_to_endpoint(url[0], headers, url[1])\n","\n","#print(json.dumps(json_response, indent=4, sort_keys=True))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lbx7D-SJ9JSw"},"source":["def append_to_csv(json_response, fileName):\n","\n","    #A counter variable\n","    counter = 0\n","\n","    #Open OR create the target CSV file\n","    csvFile = open(fileName, \"a\", newline=\"\", encoding='utf-8')\n","    csvWriter = csv.writer(csvFile)\n","\n","    #Loop through each tweet\n","    for tweet in json_response['data']:\n","        \n","        # We will create a variable for each since some of the keys might not exist for some tweets\n","        # So we will account for that\n","\n","        # 1. Author ID\n","        author_id = tweet['author_id']\n","\n","        # 1.5 Author Username\n","        for user in json_response['includes']['users']:\n","          if user['id'] == author_id:\n","            username = user['username']\n","\n","        # 2. Time created\n","        created_at = dateutil.parser.parse(tweet['created_at'])\n","\n","        # 3. Geolocation\n","        if ('geo' in tweet):   \n","            geo = tweet['geo']['place_id']\n","        else:\n","            geo = \" \"\n","\n","        # 4. Tweet ID\n","        tweet_id = tweet['id']\n","\n","        # 5. Language\n","        lang = tweet['lang']\n","\n","        # 6. Tweet metrics\n","        retweet_count = tweet['public_metrics']['retweet_count']\n","        reply_count = tweet['public_metrics']['reply_count']\n","        like_count = tweet['public_metrics']['like_count']\n","        quote_count = tweet['public_metrics']['quote_count']\n","\n","        # 7. source\n","        source = tweet['source']\n","\n","        # 8. Tweet text\n","        text = tweet['text']\n","        \n","        # Assemble all data in a list\n","        res = [author_id, username, created_at, geo, tweet_id, lang, like_count, quote_count, reply_count, retweet_count, source, text]\n","        \n","        # Append the result to the CSV file\n","        csvWriter.writerow(res)\n","        counter += 1\n","\n","    # When done, close the CSV file\n","    csvFile.close()\n","\n","    # Print the number of tweets for this iteration\n","    print(\"# of Tweets added from this response: \", counter) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wjWuPN8y7E_V"},"source":["Keywords:\n","*   #covid19ph (en/tl)\n","*   #covid19 (tl)\n","*   covid19 (tl)\n","*   coronavirus (tl)\n","*   bakuna (tl)\n","*   resbakuna (tl)\n","*   ivermiticin (tl)"]},{"cell_type":"code","metadata":{"id":"EF_Tr6MKUXpj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637072167129,"user_tz":-480,"elapsed":54941,"user":{"displayName":"Hans Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNsPj6m4ZdS6BTO53Jnuk1ST5L4kGBB9uURZWfbg=s64","userId":"17995445592224633692"}},"outputId":"bbb0552f-c0d8-4e8d-934d-93eb8a62089f"},"source":["#Inputs for tweets\n","bearer_token = auth()\n","headers = create_headers(bearer_token)\n","keyword = \"ivermectin lang:tl\" #-RT if dont want Retweets\n","start_list =    ['2021-11-10T00:00:00.000Z']\n","\n","end_list =      ['2021-11-16T00:00:00.000Z']\n","max_results = 2500\n","file_name = \"ivermectin-2021-11-16.csv\"\n","#Total number of tweets we collected from the loop\n","total_tweets = 0\n","\n","# Create file\n","csvFile = open(file_name, \"a\", newline=\"\", encoding='utf-8')\n","csvWriter = csv.writer(csvFile)\n","\n","#Create headers for the data you want to save, in this example, we only want save these columns in our dataset\n","csvWriter.writerow(['author id', 'username', 'created_at', 'geo', 'id','lang', 'like_count', 'quote_count', 'reply_count','retweet_count','source','tweet'])\n","csvFile.close()\n","\n","for i in range(0,len(start_list)):\n","\n","    # Inputs\n","    count = 0 # Counting tweets per time period\n","    max_count = 100 # Max tweets per time period\n","    flag = True\n","    #Insert previous token here if you want to continue!!!!!!!!!\n","    next_token = None \n","    \n","    # Check if flag is true\n","    while flag:\n","        # Check if max_count reached\n","        if count >= max_results:\n","            break\n","        print(\"-------------------\")\n","        print(\"Token: \", next_token)\n","        url = create_url(keyword, start_list[i],end_list[i], max_count)\n","        json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n","        result_count = json_response['meta']['result_count']\n","\n","        if 'next_token' in json_response['meta']:\n","            # Save the token to use for next call\n","            next_token = json_response['meta']['next_token']\n","            print(\"Next Token: \", next_token)\n","            if result_count is not None and result_count > 0 and next_token is not None:\n","                print(\"Start Date: \", start_list[i])\n","                append_to_csv(json_response, file_name)\n","                count += result_count\n","                total_tweets += result_count\n","                print(\"Total # of Tweets added: \", total_tweets)\n","                print(\"-------------------\")\n","                time.sleep(5)                \n","        # If no next token exists\n","        else:\n","            if result_count is not None and result_count > 0:\n","                print(\"-------------------\")\n","                print(\"Start Date: \", start_list[i])\n","                append_to_csv(json_response, file_name)\n","                count += result_count\n","                total_tweets += result_count\n","                print(\"Total # of Tweets added: \", total_tweets)\n","                print(\"-------------------\")\n","                time.sleep(5)\n","            \n","            #Since this is the final request, turn flag to false to move to the next time period.\n","            flag = False\n","            next_token = None\n","        time.sleep(5)\n","print(\"Total number of results: \", total_tweets)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-------------------\n","Token:  None\n","Endpoint Response Code: 200\n","Next Token:  b26v89c19zqg8o3fpdy5k82kwwyrkb65jg6c33nltbp8d\n","Start Date:  2021-11-10T00:00:00.000Z\n","# of Tweets added from this response:  100\n","Total # of Tweets added:  100\n","-------------------\n","-------------------\n","Token:  b26v89c19zqg8o3fpdy5k82kwwyrkb65jg6c33nltbp8d\n","Endpoint Response Code: 200\n","Next Token:  b26v89c19zqg8o3fpdy5k5yr3c2vqn62v8ucsyqpz72pp\n","Start Date:  2021-11-10T00:00:00.000Z\n","# of Tweets added from this response:  100\n","Total # of Tweets added:  200\n","-------------------\n","-------------------\n","Token:  b26v89c19zqg8o3fpdy5k5yr3c2vqn62v8ucsyqpz72pp\n","Endpoint Response Code: 200\n","Next Token:  b26v89c19zqg8o3fpdv95zw3ug8bnr8safhyaa6yns7st\n","Start Date:  2021-11-10T00:00:00.000Z\n","# of Tweets added from this response:  100\n","Total # of Tweets added:  300\n","-------------------\n","-------------------\n","Token:  b26v89c19zqg8o3fpdv95zw3ug8bnr8safhyaa6yns7st\n","Endpoint Response Code: 200\n","Next Token:  b26v89c19zqg8o3fpdv95vlgcklxfjxne6c4vwavfmv0d\n","Start Date:  2021-11-10T00:00:00.000Z\n","# of Tweets added from this response:  99\n","Total # of Tweets added:  399\n","-------------------\n","-------------------\n","Token:  b26v89c19zqg8o3fpdv95vlgcklxfjxne6c4vwavfmv0d\n","Endpoint Response Code: 200\n","-------------------\n","Start Date:  2021-11-10T00:00:00.000Z\n","# of Tweets added from this response:  46\n","Total # of Tweets added:  445\n","-------------------\n","Total number of results:  445\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"54g2dQC5-0OQ","executionInfo":{"status":"ok","timestamp":1637072167130,"user_tz":-480,"elapsed":22,"user":{"displayName":"Hans Calvin Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNsPj6m4ZdS6BTO53Jnuk1ST5L4kGBB9uURZWfbg=s64","userId":"17995445592224633692"}},"outputId":"f0143e58-dc36-41fc-cfde-771bf3d0c31c"},"source":["from google.colab import files\n","files.download(file_name)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_17dd706e-572c-446e-ac7c-c0d2334ae0fc\", \"ivermectin-2021-11-16.csv\", 108259)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}